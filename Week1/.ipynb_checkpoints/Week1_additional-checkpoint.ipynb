{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1주차 추가 요약 자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 주 발표의 내용이 부실해서 추가 자료를 만들어봅니다!\n",
    "아마 다들 잘 이해하실 수 있을거에요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH2 Statistical Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 머신러닝이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $Y = f(X) + \\epsilon$ 에서 $f$를 구하는 것!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model의 종류는 어떤게 있고 어떨 때 쓸까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![models](models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 예측력? 설명력?\n",
    "    - 더 정확한 Y를 뽑고싶다! = 예측력(Prediction Accuracy)\n",
    "    - 왜 그런 Y가 나왔는지 알고싶다! = 설명력(Model Interpretability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Supervised Learning(지도학습) vs Unsupervised Learning(비지도학습)\n",
    "    - Supervised Learning : Label을 정해놓고, 함수를 통해 그 Label들로 분류하는 것,\n",
    "    예를 들면 분리수거\n",
    "    - Unsupervised Learning : 일단 비슷한 애들끼리 모아보고 걔네들한테 이름 붙이기\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그래서 저 중에 이번 스터디 땐 어떤것을 배울 예정인가요?\n",
    "    - Logistic Regression, LDA, QDA, KNN : 4장\n",
    "    - Lasso : 6장\n",
    "    - 다항선형회귀분석(Polynomial Regression) : 7장\n",
    "    - 의사결정나무(decision tree), Random Forest 등 : 8장\n",
    "    - SVM(Support Vector Machine), SVR(Support Vector Regressor) : 9장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parametric Methods (모수적 추정) vs Non-Parametric Methods(비모수 추정)\n",
    "    - Parametric Methods : $f$가 어떠한 분포를 가지고 있다고 가정한다! (ex. 회귀분석에선 $\\epsilon$이 standard normal($Normal(0,1)$)이라고 가정)\n",
    "        - 예를 들면 $f(X) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p$(회귀분석에서 봤죠?)\n",
    "        - 여기서 $\\beta$들에 들어갈 적절한 값을 찾는 것이 바로 모수적인 방법! \n",
    "        - 모수가 어떠냐에 따라 변수가 어떤 영향을 가지는지 설명 가능 -> 해석력이 높다\n",
    "        - But, 분포에 대한 가정이 틀린 경우는 정확도가 크게 떨어짐\n",
    "        - 우리가 배울 모델 중엔 Logistic Regression, LDA, QDA, KNN, Polynomial Regression 등이 해당\n",
    "    - Non-parametric Methods : $f$에 대한 어떠한 가정도 하지 않음\n",
    "        - 보통 갯수를 세거나, rank를 주거나, 거리를 측정하는 등의 방식으로 진행함\n",
    "        - 분포에 대한 가정을 하지 않기 때문에 그러한 가정이 틀려서 일어나는 error는 없음 -> 예측력이 높다\n",
    "        - But 어떤 변수가 어떻게 얼마나 결과에 영향을 미치는지 해석은 거의 불가능\n",
    "        - 우기가 배울 모델 중엔 Decision Tree 기반 모델들(Random Forest, Boost 등), SVM, SVR, KNN 등이 해당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bias : 데이터와 예측값간의 차이(즉 어떠한 데이터로 만든 모델이 그 데이터를 얼마나 정확하게 반영하는지를 나타냄)\n",
    "- Variance : 모델과 모델간의 차이(즉 같은 모집단에서 뽑은 서로 다른 샘플 데이터로 모델을 만들었을 때, 그 모델들 간에 얼마나 큰 차이가 있는지)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하지만 Bias와 Variance는 Tradeoff 관계에 있기 때문에, 둘 모두를 최소화시킬 수는 없음!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bv](bv1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 이런 데이터가 있다고 생각해보자. 이 데이터를 가지고 만들 수 있는 가장 정확한 모델은 당연히 이런 모델이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bv2](bv2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만, 같은 모집단에서 뽑은 다른 샘플이 들어온다면?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bv3](bv3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 모델이 확확 바뀐다! 그리고 이런 식으로 만들어진 모델은 새로운 데이터를 예측할 때 정확도가 떨어진다 ㅠㅠ -> 즉 Variance가 크다!\n",
    "\n",
    "## 우리는 이것을 over fitting 이라고 한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But 적절하게 단순한 모델을 만든다면?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bv4](bv4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 바뀐다고 해서 모델이 크게 달라지지도 않고 새로운 데이터를 예측할 때 오차도 더 작다! -> Variance 작음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "근데 더 복잡한 데이터가 들어온다면??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bs5](bs5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 데이터가 들어온다면, 위와 같은 간단한 선형식으로는 오차가 너무 크다! -> Bias가 높다\n",
    "\n",
    "## 우리는 이것을 under fitting이라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 즉, 너무 복잡하지도 않고 너무 간단하지도 않은 \n",
    "\n",
    "# 적절한 모델을 만드는 것이 중요하다 !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bs6](bs6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "책에 있는 예시를 보면, Y축이 Error X축이 복잡도를 나타낸다고 생각하자. 빨간색 곡선인 'Test MSE'는 어느 순간 까지는 내려가지만, 그 이후로는 쭉 증가한다. Overfitting되었기 때문이다. 반면 회색 곡선인 'Train MSE'는 계속 낮아지고, 너무 간단한 경우는 MSE가 높다. Underfitting되었기 때문이다. 따라서 복잡도 5 정도에서 형성되는 적절한 복잡도를 찾는 것이 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
