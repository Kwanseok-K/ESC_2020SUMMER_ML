{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1주차 추가 요약 자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 주 발표의 내용이 부실해서 추가 자료를 만들어봅니다!\n",
    "아마 다들 잘 이해하실 수 있을거에요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH2 Statistical Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 머신러닝이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $Y = f(X) + \\epsilon$ 에서 $f$를 구하는 것!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model의 종류는 어떤게 있고 어떨 때 쓸까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![models](models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 예측력? 설명력?\n",
    "    - 더 정확한 Y를 뽑고싶다! = 예측력(Prediction Accuracy)\n",
    "    - 왜 그런 Y가 나왔는지 알고싶다! = 설명력(Model Interpretability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Supervised Learning(지도학습) vs Unsupervised Learning(비지도학습)\n",
    "    - Supervised Learning : Label을 정해놓고, 함수를 통해 그 Label들로 분류하는 것,\n",
    "    예를 들면 분리수거\n",
    "    - Unsupervised Learning : 일단 비슷한 애들끼리 모아보고 걔네들한테 이름 붙이기\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 그래서 저 중에 이번 스터디 땐 어떤것을 배울 예정인가요?\n",
    "    - Logistic Regression, LDA, QDA, KNN : 4장\n",
    "    - Lasso : 6장\n",
    "    - 다항선형회귀분석(Polynomial Regression) : 7장\n",
    "    - 의사결정나무(decision tree), Random Forest 등 : 8장\n",
    "    - SVM(Support Vector Machine), SVR(Support Vector Regressor) : 9장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parametric Methods (모수적 추정) vs Non-Parametric Methods(비모수 추정)\n",
    "    - Parametric Methods : $f$가 어떠한 분포를 가지고 있다고 가정한다! (ex. 회귀분석에선 $\\epsilon$이 standard normal($Normal(0,1)$)이라고 가정)\n",
    "        - 예를 들면 $f(X) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + ... + \\beta_pX_p$(회귀분석에서 봤죠?)\n",
    "        - 여기서 $\\beta$들에 들어갈 적절한 값을 찾는 것이 바로 모수적인 방법! \n",
    "        - 모수가 어떠냐에 따라 변수가 어떤 영향을 가지는지 설명 가능 -> 해석력이 높다\n",
    "        - But, 분포에 대한 가정이 틀린 경우는 정확도가 크게 떨어짐\n",
    "        - 우리가 배울 모델 중엔 Logistic Regression, LDA, QDA, Polynomial Regression 등이 해당\n",
    "    - Non-parametric Methods : $f$에 대한 어떠한 가정도 하지 않음\n",
    "        - 보통 갯수를 세거나, rank를 주거나, 거리를 측정하는 등의 방식으로 진행함\n",
    "        - 분포에 대한 가정을 하지 않기 때문에 그러한 가정이 틀려서 일어나는 error는 없음 -> 예측력이 높다\n",
    "        - But 어떤 변수가 어떻게 얼마나 결과에 영향을 미치는지 해석은 거의 불가능\n",
    "        - 우리가 배울 모델 중엔 Decision Tree 기반 모델들(Random Forest, Boost 등), SVM, SVR, KNN 등이 해당"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bias : 데이터와 예측값간의 차이(즉 어떠한 데이터로 만든 모델이 그 데이터를 얼마나 정확하게 반영하는지를 나타냄)\n",
    "- Variance : 모델과 모델간의 차이(즉 같은 모집단에서 뽑은 서로 다른 샘플 데이터로 모델을 만들었을 때, 그 모델들 간에 얼마나 큰 차이가 있는지)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하지만 Bias와 Variance는 Tradeoff 관계에 있기 때문에, 둘 모두를 최소화시킬 수는 없음!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bv](bv1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어 이런 데이터가 있다고 생각해보자. 이 데이터를 가지고 만들 수 있는 가장 정확한 모델은 당연히 이런 모델이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bv2](bv2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만, 같은 모집단에서 뽑은 다른 샘플이 들어온다면?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bv3](bv3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 모델이 확확 바뀐다! 그리고 이런 식으로 만들어진 모델은 새로운 데이터를 예측할 때 정확도가 떨어진다 ㅠㅠ -> 즉 Variance가 크다!\n",
    "\n",
    "## 우리는 이것을 over fitting 이라고 한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But 적절하게 단순한 모델을 만든다면?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bv4](bv4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 바뀐다고 해서 모델이 크게 달라지지도 않고 새로운 데이터를 예측할 때 오차도 더 작다! -> Variance 작음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "근데 더 복잡한 데이터가 들어온다면??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bs5](bs5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 데이터가 들어온다면, 위와 같은 간단한 선형식으로는 오차가 너무 크다! -> Bias가 높다\n",
    "\n",
    "## 우리는 이것을 under fitting이라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 즉, 너무 복잡하지도 않고 너무 간단하지도 않은 \n",
    "\n",
    "# 적절한 모델을 만드는 것이 중요하다 !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bs6](bs6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "책에 있는 예시를 보면, Y축이 Error X축이 복잡도를 나타낸다고 생각하자. 빨간색 곡선인 'Test MSE'는 어느 순간 까지는 내려가지만, 그 이후로는 쭉 증가한다(초록색). Overfitting되었기 때문이다. 반면 회색 곡선인 'Train MSE'는 계속 낮아지고, 너무 간단한 경우는 MSE가 높다(노랑색). Underfitting되었기 때문이다. 따라서 복잡도 5 정도에서 형성되는 적절한 복잡도를 찾는 것이 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 목적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주어진 X 변수를 가지고 '정해진' Class(Y)에 분류하는 것!\n",
    "\n",
    "- Class가 2개이면 binary classification, 2개 초과일 경우는 multi-class classification이라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 즉, $P(Y = y | X = x_0 )$ 를 구하는 것이 목적이다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여기서 $y$는 특정 class을 뜻하고, $x_0$는 주어진 x변수를 뜻한다. 즉 $x_0$라는 데이터가 주어졌을 때, 그 데이터가 $y$라는 class에 속할 확률을 구하는 것이다!\n",
    "\n",
    "- notation을 더 간단하게 하기 위해 $P(C_k|x)$ 라고 하겠다. 여기서 $C_k$는 $k$라는 Class에 속해있다는 뜻이고, $x$는 위와 마찬가지고 주어진 data이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 챕터에서는 이 $P(C_k|x)$를 구하는 방법 중, LDA, QDA, Logistic Regression에 대해 배워보도록 하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 전반적인 방법론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sigmoid? Softmax?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![C1](C1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 데이터가 있다고 생각해보자. 만약 이 데이터에 선형 회귀분석을 실시한다면?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![C2](C2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 방식에는 문제가 있다! 바로 확률의 정의를 위반한다는 점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cf) 확률의 정의란?\n",
    "    1. 0과 1 사이의 값이다\n",
    "    2. 다 더하면 1이다\n",
    "    3. 두 사건의 교집합이 없으면, 둘 모두가 일어날 확률은 둘 각각이 일어날 확률을 더한 것과 같다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바로 이 1번 정의를 위반한다. 음수가 나오기도 하고 1보다 큰 값이 나오기도 하기 때문이다. 그렇기 때문에, 확률값으로 나타내기 위해 등장한 것이 sigmoid(2 class)함수와 softmax(multiclass)함수이다. sigmoid를 예로 들자면, 이러한 그래프가 그려진다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![C3](C3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0과 1 사이에 온 것을 알 수 있다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 위한 방법이 $P(C_k|x)$를 $\\frac{1}{1+exp(-a)} = \\sigma(a)$로 계산하는 것이다!. 이것이 왜 0과 1 사이에 올 수 밖에 없는지는 직관적으로 알 수 있을 것이다.(if $a \\rightarrow \\infty , exp(-a) \\rightarrow 0, \\sigma(a) \\rightarrow 1$ & $a \\rightarrow -\\infty , exp(-a) \\rightarrow \\infty, \\sigma(a) \\rightarrow 0$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 $a$는 우리가 회귀분석 시간에 배운 $W^TX + w_0$이며, $a$를 이와 같은 식으로 변환하는 함수 $\\sigma$를 'sigmoid'함수라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax 함수는 일단 이것을 multiclass case로 일반화 했다고 이해해놓자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LDA&QDA vs Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA&QDA와 Logistic Regression의 차이는 바로 최적의 $W$, $w_0$를 찾는 방법론의 차이이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LDA & QDA의 방법론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 둘은 간접적인 방식을 통해 최적의 $W$, $w_0$를 구한다. 바로 베이즈 정리를 이용한 방법이다. 일단 설명은 Binary Classification을 가지고 하겠다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "베이즈 정리를 이용하면\n",
    "\n",
    "데이터가 주어졌을 때, 그 데이터가 1번 class에 속할 확률은 다음과 같이 구할 수 있다.\n",
    "\n",
    "$P(C_1|x) = \\frac{P(C_1)P(X|C_1)}{\\Sigma P(C_k)P(x|C_k)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때, 우리는 $P(X|C_1)$을 평균이 $\\mu_k$이고 공분산행렬이 $\\Sigma$인 multivariate normal distribution을 가정한다. 이 가정을 가지고 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![C4](C4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때, $\\pi = P(C_1)$이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 likelihood function을 $\\pi, \\mu_k, \\Sigma$로 편미분함으로써 이 값들의 MLE를 구하고 이 값들을 $P(C_1)$, $P(X|C_1)$에 대입하여 $P(C_1|x)$를 구하고(구체적인 편미분 방법은 PRML 200~201P 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{P(C_1)P(X|C_1)}{\\Sigma P(C_k)P(x|C_k)}$ = $\\frac{1}{1+exp(-a)} = \\sigma(a)$ 이 방정식을 만족하는 $a = W^TX+w_0$을 구해 최적의 $W, w_0$를 구하는 것이다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 구할 때, class간에 동일한 공분산행렬 $\\Sigma$를 가정하면 Decision Boundary가 직선으로 나오는 LDA(Linear Descriminant Analysis)가 되는것이고, 각자 다른 $\\Sigma$를 가진다고 가정하면 QDA(Quadratic Descriminant Analysis)가 되는 것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Logistic Regression의 방법론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 방법은 간접적으로 decompose한 식들의 MLE를 구해 합쳐서 $W, w_0$를 구하는 방식이 아닌, 직접적으로 $P(C_1|x) = \\frac{1}{1+exp(-a)} = \\sigma(a = W^TX+w_0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 식에서 Gradient Descent 방식을 통해 $W^T, w_0$의 최적값을 구하는 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "목요일 정규 세션에서 배운 것과 마찬가지로, loss function을 Cross Entropy로 설정하고 이를 최소화하는 $W, w_0$를 구하는데, 이 과정은 학부 수준을 뛰어 넘는 것이다. 따라서 그냥 logistic regresson 함수를 돌리면, 컴퓨터가 굉장히 고생하는구나~ 정도로 생각하면 될 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혹시나 그 방법을 공부해보고 싶다면 단톡방에 올린 PRML책 205~208P를 읽어보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN은 CH2 Slide에 있는 내용이 다라 생략! 그냥 비모수적인 방법이다 ~ 라고 생각하시면 됩니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이 요약글로 이해가 가시면 좋겠네요 ㅜㅜ 질문이 있으시다면 언제든지 말씀해주세요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
